# CLIP-trainer

A small library that reproduces the CLIP model for {text, image} pairs using a standard transformer encoder for the text encoder, and a ResNet for the image encoder.
The files are kept to what's minimally needed for reproducing, and lots of comments should help to explain edge cases that aren't entirely clear in the paper.
